mnlismall:{'hidden_fc': 172, 'number_layers': 2, 'lr': 0.0001, 'CNNs': {'hidden_fc': 75, 'number_layers': 2, 'kernel_size': 11, 'skip': False}, 'pooling': 'max', 'freeze_base': False, 'Attention': {}, 'task_id': 38, 'config_id': '37'}

sst2small: {'hidden_fc': 82, 'number_layers': 1, 'lr': 7.817095442269968e-05, 'CNNs': {}, 'pooling': 'max', 'freeze_base': False, 'Attention': {'num_heads': 8, 'number_layers': 1}, 'task_id': 28, 'config_id': '27'}

mrpcsmall: {'hidden_fc': 60, 'number_layers': 2, 'lr': 5.9659933383060565e-05, 'CNNs': {'hidden_fc': 90, 'number_layers': 2, 'kernel_size': 3, 'skip': True}, 'pooling': 'mean', 'freeze_base': False, 'Attention': {}, 'task_id': 23, 'config_id': '22'}

colasmall: {'hidden_fc': 115, 'number_layers': 1, 'lr': 9.147134628810136e-05, 'CNNs': {}, 'pooling': '[CLS]', 'freeze_base': False, 'Attention': {}, 'task_id': 30, 'config_id': '29'}

qqpsmall: {'hidden_fc': 122, 'number_layers': 2, 'lr': 3.5634410961969775e-05, 'CNNs': {'hidden_fc': 43, 'number_layers': 1, 'kernel_size': 11, 'skip': False}, 'pooling': '[CLS]', 'Attention': {}, 'task_id': 23, 'config_id': '23'}

rtesmall:{'hidden_fc': 99, 'number_layers': 1, 'lr': 3.42502276457385e-05, 'CNNs': {'hidden_fc': 14, 'number_layers': 5, 'kernel_size': 5, 'skip': True}, 'pooling': 'mean', 'Attention': {}, 'task_id': 20, 'config_id': '20'}




rte:{'hidden_fc': 6, 'number_layers': 1, 'lr': 2.044894027837729e-05, 'CNNs': {}, 'pooling': '[CLS]', 'Attention': {}, 'task_id': 19, 'config_id': '19'}

mnli:{'hidden_fc': 117, 'number_layers': 3, 'lr': 1.4611774163625117e-05, 'CNNs': {'hidden_fc': 9, 'number_layers': 3, 'kernel_size': 11, 'skip': True}, 'pooling': 'max', 'Attention': {}, 'task_id': 19, 'config_id': '19'}

qqp: {'hidden_fc': 87, 'number_layers': 1, 'lr': 3.0126906059830935e-05, 'CNNs': {'hidden_fc': 159, 'number_layers': 2, 'kernel_size': 7, 'skip': True}, 'pooling': 'max', Attention': {}, 'config_id': '6'}
accuracy after 2 epochs: 0.899899959564209 time per epoch 2961.5434758663177

cola: {'hidden_fc': 5, 'number_layers': 1, 'lr': 3.9218433502182145e-05, 'CNNs': {}, 'pooling': '[CLS]', 'freeze_base': False, 'Attention': {}, 'task_id': 44, 'config_id': '43'}

mrpc: {'hidden_fc': 74, 'number_layers': 4, 'lr': 3.7563328159172625e-05, 'CNNs': {'hidden_fc': 107, 'number_layers': 4, 'kernel_size': 7, 'skip': True}, 'pooling': '[CLS]', 'freeze_base': False, 'Attention': {'num_heads': 16, 'number_layers': 4}, 'task_id': 14, 'config_id': '13'}

sst2: {'hidden_fc': 50, 'number_layers': 5, 'lr': 4.460045089896744e-05, 'CNNs': {}, 'pooling': '[CLS]', 'freeze_base': False, 'Attention': {'num_heads': 16, 'number_layers': 5}, 'task_id': 18, 'config_id': '17'}


small combined:
{'hidden_fc': 39, 'number_layers': 2, 'lr': 3.616616520956171e-05, 'CNNs': {}, 'pooling': 'mean', 'freeze_base': False, 'Attention': {'num_heads': 4, 'number_layers': 1}, 'task_id': 6, 'config_id': '6'}

large combined:
{'hidden_fc': 69, 'number_layers': 1, 'lr': 1.6889768951768413e-05, 'CNNs': {'hidden_fc': 40, 'number_layers': 1, 'kernel_size': 11, 'skip': True}, 'pooling': 'mean', 'Attention': {'num_heads': 1, 'number_layers': 4}, 'task_id': 48, 'config_id': '48'}

